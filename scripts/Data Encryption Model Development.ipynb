{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "- bring in target from binary_categories table for data encryption practices ONLY FOR sites in OPP-115\n",
    "- bring in features from segment table ONLY FOR sites in OPP-115\n",
    "- check for length!\n",
    "- set up text processing functions\n",
    "- set up BOW >> TFIDF >> Naive Bayes pipeline\n",
    "- train-test-split data\n",
    "- fit, predict, check classification\n",
    "- wash, rinse, repeat\n",
    "- pickle out trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Database imports and credentials\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Establish database connection\n",
    "dbname = 'beforeiagree_db'\n",
    "username = 'peterostendorp'\n",
    "\n",
    "#Create engine\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target-level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT \"Policy UID\", segment_id, data_security FROM binary_segment_categories\n",
    "WHERE binary_segment_categories.\"Policy UID\" IN\n",
    "(SELECT \"Policy UID\" FROM sites\n",
    "WHERE sites.\"In 115 Set?\" IS TRUE);\n",
    "\"\"\"\n",
    "\n",
    "targets_segments = pd.read_sql_query(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3792 entries, 0 to 3791\n",
      "Data columns (total 3 columns):\n",
      "Policy UID       3792 non-null int64\n",
      "segment_id       3792 non-null int64\n",
      "data_security    3792 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 89.0 KB\n"
     ]
    }
   ],
   "source": [
    "targets_segments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3625\n",
       "1     167\n",
       "Name: data_security, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_segments['data_security'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044040084388185657"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_segments['data_security'].value_counts()[1]/targets['data_security'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: only about 4.4% of segments in these documents pertain to this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57\n",
       "0    21\n",
       "2    20\n",
       "3     9\n",
       "6     4\n",
       "4     3\n",
       "7     1\n",
       "Name: data_security, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_segments.groupby('Policy UID').sum()['data_security'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But most **documents** have at least 1 mention, if not several."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get segments associated with policies in the OPP-115 corpus\n",
    "sql = \"\"\"\n",
    "SELECT * FROM segments\n",
    "WHERE \"Policy UID\" IN \n",
    "(SELECT \"Policy UID\" FROM sites\n",
    "WHERE \"In 115 Set?\" = TRUE)\n",
    "\"\"\"\n",
    "\n",
    "segments = pd.read_sql_query(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy UID</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;strong&gt; Privacy Policy &lt;/strong&gt; &lt;br&gt; &lt;br&gt; &lt;s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>This privacy policy does not apply to Sites ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>By visiting our Sites, you are accepting the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;strong&gt; What Information Is Collected? &lt;/stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;strong&gt; Personally Identifiable Information &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy UID  segment_id                                           segments\n",
       "0          20           0  <strong> Privacy Policy </strong> <br> <br> <s...\n",
       "1          20           1  This privacy policy does not apply to Sites ma...\n",
       "2          20           2  By visiting our Sites, you are accepting the p...\n",
       "3          20           3  <strong> What Information Is Collected? </stro...\n",
       "4          20           4  <strong> Personally Identifiable Information <..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initial text-processing function for segments... not much needed here.\n",
    "#Set up our initial text cleaning function\n",
    "def text_process_segment(doc):\n",
    "    \"\"\"\n",
    "    1. remove stopwords\n",
    "    2. remove HTML tags\n",
    "    \"\"\"\n",
    "    lst = [word for word in doc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return [word for word in lst if re.search(r'\\<.*\\>',word) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up an sklearn pipeline that processes policies, transforms them into a BOW model, applies TFIDF metric,\n",
    "#then develops a Naive Bayes classifier.\n",
    "data_encryption_NB_segment = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process_segment)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6469, 3)\n",
      "(3792, 3)\n"
     ]
    }
   ],
   "source": [
    "print(segments.shape)\n",
    "print(targets_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6469, 3792]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e6c6b433dcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Split data using 30%/70% split, random seed is my birthday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m segments_train, segments_test, targets_train, targets_test = train_test_split(segments['segments'], \n\u001b[0;32m----> 3\u001b[0;31m     targets_segments['data_security'], test_size=0.3, random_state=84)\n\u001b[0m",
      "\u001b[0;32m/Users/peterostendorp/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peterostendorp/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peterostendorp/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6469, 3792]"
     ]
    }
   ],
   "source": [
    "#Split data using 30%/70% split, random seed is my birthday\n",
    "segments_train, segments_test, targets_train, targets_test = train_test_split(segments['segments'], \n",
    "    targets_segments['data_security'], test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy-level model\n",
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select category targets\n",
    "sql = \"\"\"\n",
    "SELECT \"Policy UID\",data_security FROM binary_policy_categories\n",
    "WHERE \"Policy UID\" IN \n",
    "(SELECT \"Policy UID\" FROM sites\n",
    "WHERE \"In 115 Set?\" = TRUE)\n",
    "\"\"\"\n",
    "\n",
    "targets_policies = pd.read_sql_query(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy UID</th>\n",
       "      <th>data_security</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy UID  data_security\n",
       "0          20              1\n",
       "1          21              1\n",
       "2          26              1\n",
       "3          32              1\n",
       "4          33              1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_policies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select original policies as features\n",
    "sql = \"\"\"\n",
    "SELECT \"Policy UID\", policy_text FROM sites\n",
    "WHERE sites.\"In 115 Set?\" = TRUE\n",
    "\"\"\"\n",
    "\n",
    "policies = pd.read_sql_query(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy UID</th>\n",
       "      <th>policy_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>&lt;strong&gt; Privacy Policy &lt;/strong&gt; &lt;br&gt; &lt;br&gt; &lt;s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>IMDb Privacy Notice &lt;br&gt; &lt;br&gt;|||Last Updated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>&lt;strong&gt; Privacy Policy &lt;/strong&gt; &lt;br&gt; &lt;br&gt; La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Vox Media Privacy Policy &lt;br&gt; &lt;br&gt;|||&lt;strong&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Full Privacy Policy &lt;br&gt; &lt;br&gt; Last updated: 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy UID                                        policy_text\n",
       "0          20  <strong> Privacy Policy </strong> <br> <br> <s...\n",
       "1          21  IMDb Privacy Notice <br> <br>|||Last Updated, ...\n",
       "2          26  <strong> Privacy Policy </strong> <br> <br> La...\n",
       "3          32  Vox Media Privacy Policy <br> <br>|||<strong> ...\n",
       "4          33  Full Privacy Policy <br> <br> Last updated: 14..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up our initial text cleaning function\n",
    "def text_process_policy(doc):\n",
    "    \"\"\"\n",
    "    1. remove punctuation\n",
    "    2. remove stopwords\n",
    "    3. remove HTML tags\n",
    "    4. remove '|||' inserted into corpus documents only\n",
    "    \"\"\"\n",
    "    lst = [word for word in doc.split() if re.search(r'\\<.*\\>',word) is None]\n",
    "    lst = ' '.join(lst)\n",
    "    lst = [char for char in lst if char not in string.punctuation]\n",
    "    lst = ''.join(lst)    \n",
    "    lst = [word for word in lst.split() if word.lower() not in stopwords.words('english')]\n",
    "    lst = [word for word in lst if word.replace('|||','')]\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up an sklearn pipeline that processes policies, transforms them into a BOW model, applies TFIDF metric,\n",
    "#then develops a Naive Bayes classifier.\n",
    "data_encryption_NB_policy = Pipeline([\n",
    "    ('bow',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data using 30%/70% split, random seed is my birthday\n",
    "policies_train, policies_test, targets_train, targets_test = train_test_split(policies['policy_text'], \n",
    "    targets_policies['data_security'], test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policies_train = policies_train.map(text_process_policy)\n",
    "policies_test = policies_test.map(text_process_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4      Full Privacy Policy Last updated 14 January 20...\n",
       "22     reddit privacy policy effective Apr 14 2015 pr...\n",
       "14     VIPrivacy Policy Type Information Service Coll...\n",
       "112    Privacy Policy updated August 26 2014 Commitme...\n",
       "98     Last updated October 1 2013 Games Inca United ...\n",
       "Name: policy_text, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now fit/train the model\n",
    "data_encryption_NB_policy.fit(policies_train,targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "preds_policy = data_encryption_NB_policy.predict(policies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4]\n",
      " [ 0 31]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         4\n",
      "          1       0.89      1.00      0.94        31\n",
      "\n",
      "avg / total       0.78      0.89      0.83        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterostendorp/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(confusion_matrix(targets_test,preds_policy))\n",
    "print(classification_report(targets_test,preds_policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {}\n",
    "reports = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "- consider different tokenizer\n",
    "- bigrams?\n",
    "- pass in legal dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up an sklearn pipeline that processes policies, transforms them into a BOW model, applies TFIDF metric,\n",
    "#then develops an AdaBoost classifier with 100 weak learners.\n",
    "data_encryption_ADA_policy = Pipeline([\n",
    "    ('bow',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',AdaBoostClassifier(n_estimators=100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now fit/train the model\n",
    "data_encryption_ADA_policy.fit(policies_train,targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "preds_policy = data_encryption_ADA_policy.predict(policies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  1]\n",
      " [ 7 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.75      0.43         4\n",
      "          1       0.96      0.77      0.86        31\n",
      "\n",
      "avg / total       0.88      0.77      0.81        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "n_estimators = data_encryption_ADA_policy.named_steps['classifier'].n_estimators\n",
    "cms[n_estimators] = confusion_matrix(targets_test,preds_policy)\n",
    "reports[n_estimators] = classification_report(targets_test,preds_policy)\n",
    "print(cms[n_estimators])\n",
    "print(reports[n_estimators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/data_encryption_ADA_policy.pkl', 'wb') as file:\n",
    "    pickle.dump(data_encryption_ADA_policy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up an sklearn pipeline that processes policies, transforms them into a BOW model, applies TFIDF metric,\n",
    "#then develops an AdaBoost classifier with 100 weak learners.\n",
    "data_encryption_RF_policy = Pipeline([\n",
    "    ('bow',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit\n",
    "data_encryption_RF_policy.fit(policies_train,targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "preds_policy = data_encryption_RF_policy.predict(policies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report\n",
    "cm = confusion_matrix(targets_test,preds_policy)\n",
    "cr = classification_report(targets_test,preds_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2]\n",
      " [ 4 27]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.50      0.40         4\n",
      "          1       0.93      0.87      0.90        31\n",
      "\n",
      "avg / total       0.86      0.83      0.84        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Balanced weighting\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('filename.pickle', 'wb') as handle:\n",
    "#     pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../pickles/data_encryption_RF_policy.pkl', 'wb') as file:\n",
    "    pickle.dump(data_encryption_RF_policy,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
